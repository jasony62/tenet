tenet.kafka.producer.acks=1
tenet.kafka.producer.batch-size=16384
tenet.kafka.producer.buffer-memory=33554432
tenet.kafka.producer.bootstrap-servers=localhost:9092
#tenet.kafka.producer.client-dns-lookup=default
#tenet.kafka.producer.client-id=
#tenet.kafka.producer.compression-type=none
#ms
#tenet.kafka.producer.connections-max-idle=540000
#tenet.kafka.producer.delivery-timeout=120000
#tenet.kafka.producer.enable-idempotence=false
#tenet.kafka.producer.interceptor-classes = []
tenet.kafka.producer.key-serializer=org.apache.kafka.common.serialization.ByteArraySerializer
tenet.kafka.producer.properties.linger.ms=1
#tenet.kafka.producer.max-block=60000 #ms
#tenet.kafka.producer.flight-requests=5
#tenet.kafka.producer.max-request-size=1048576
#metric.reporters = []
#metrics.num.samples = 2
#metrics.recording.level = INFO
#metrics.sample.window.ms = 30000
#partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
#receive.buffer.bytes = 32768
#reconnect.backoff.max.ms = 1000
#reconnect.backoff.ms = 50
#request.timeout.ms = 30000
#sasl.client.callback.handler.class = null
#sasl.jaas.config = null
#sasl.kerberos.kinit.cmd = /usr/bin/kinit
#sasl.kerberos.min.time.before.relogin = 60000
#sasl.kerberos.service.name = null
#sasl.kerberos.ticket.renew.jitter = 0.05
#sasl.kerberos.ticket.renew.window.factor = 0.8
#sasl.login.callback.handler.class = null
#sasl.login.class = null
#sasl.login.refresh.buffer.seconds = 300
#sasl.login.refresh.min.period.seconds = 60
#sasl.login.refresh.window.factor = 0.8
#sasl.login.refresh.window.jitter = 0.05
#sasl.mechanism = GSSAPI
#security.protocol = PLAINTEXT
#send.buffer.bytes = 131072
#ssl.cipher.suites = null
#ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
#ssl.endpoint.identification.algorithm = https
#ssl.key.password = null
#ssl.keymanager.algorithm = SunX509
#ssl.keystore.location = null
#ssl.keystore.password = null
#ssl.keystore.type = JKS
#ssl.protocol = TLS
#ssl.provider = null
#ssl.secure.random.implementation = null
#ssl.trustmanager.algorithm = PKIX
#ssl.truststore.location = null
#ssl.truststore.password = null
#ssl.truststore.type = JKS
tenet.kafka.producer.retries=0
#tenet.kafka.producer.retry-backoff = 100
#transaction.timeout.ms = 60000
#transactional.id = null
tenet.kafka.producer.value-serializer=org.apache.kafka.common.serialization.ByteArraySerializer
#####################
#tenet.kafka.consumer.create-topics = true
#auto.commit.interval.ms = 5000
tenet.kafka.consumer.auto-offset-reset=earliest
tenet.kafka.consumer.bootstrap-servers=localhost:9092
#tenet.kafka.consumer.check-crcs=true
tenet.kafka.consumer.client-id=consumer0
#tenet.kafka.consumer.client-rack =
#connections.max.idle.ms=540000
#default.api.timeout.ms
tenet.kafka.consumer.enable-auto-commit=false
#exclude.internal.topics = true
#fetch.max.bytes = 52428800
#fetch.max.wait.ms = 500
#	fetch.min.bytes = 1
tenet.kafka.consumer.group-id=test-consumer
#group.instance.id = null
tenet.kafka.consumer.heartbeat-interval=3000
#interceptor.classes = []
#internal.leave.group.on.close = true
#isolation.level = read_uncommitted
tenet.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
#max.partition.fetch.bytes = 1048576
tenet.kafka.consumer.max-poll-interval-ms=3000
tenet.kafka.consumer.max-poll-records=40
#	metadata.max.age.ms = 300000
#   partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
#  receive.buffer.bytes = 65536
#	reconnect.backoff.max.ms = 1000
#	reconnect.backoff.ms = 50
#	request.timeout.ms = 30000
#	retry.backoff.ms = 100
#	sasl.client.callback.handler.class = null
#	sasl.jaas.config = null
#	sasl.kerberos.kinit.cmd = /usr/bin/kinit
#	sasl.kerberos.min.time.before.relogin = 60000
#	sasl.kerberos.service.name = null
#	sasl.kerberos.ticket.renew.jitter = 0.05
#	sasl.kerberos.ticket.renew.window.factor = 0.8
#	sasl.login.callback.handler.class = null
#	sasl.login.class = null
#	sasl.login.refresh.buffer.seconds = 300
#	sasl.login.refresh.min.period.seconds = 60
#	sasl.login.refresh.window.factor = 0.8
#	sasl.login.refresh.window.jitter = 0.05
#	sasl.mechanism = GSSAPI
#security.protocol = PLAINTEXT
#	send.buffer.bytes = 131072
tenet.kafka.consumer.session.timeout.ms=10000
#	ssl.cipher.suites = null
#	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
#	ssl.endpoint.identification.algorithm = https
#	ssl.key.password = null
#	ssl.keymanager.algorithm = SunX509
#	ssl.keystore.location = null
#	ssl.keystore.password = null
#	ssl.keystore.type = JKS
#	ssl.protocol = TLS
#	ssl.provider = null
#	ssl.secure.random.implementation = null
#	ssl.trustmanager.algorithm = PKIX
#	ssl.truststore.location = null
#	ssl.truststore.password = null
#	ssl.truststore.type = JKS
tenet.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
#myself
tenet.kafka.consumer.offset-flush=1500
#sink mysql and mongo common config
tenet.sink.batch-size=40
#change.data.capture.handler =
#	collection =
# 	database = kafka_demo
# delete.on.null.values = false
tenet.sink.id-strategy=io.ctsi.tenet.kafka.mongodb.sink.processor.id.strategy.KafkaMetaDataStrategy
#document.id.strategy.overwrite.existing = false
#document.id.strategy.partial.key.projection.list =
#document.id.strategy.partial.key.projection.type =
#document.id.strategy.partial.value.projection.list =
#document.id.strategy.partial.value.projection.type =
#document.id.strategy.uuid.format = string
#errors.log.enable = false
#errors.tolerance = none
#field.renamer.mapping = []
#field.renamer.regexp = []
#key.projection.list =
#key.projection.type = none
tenet.sink.max-retries=3
#post.processor.chain = [io.ctsi.tenet.kafka.mongodb.sink.processor.DocumentIdAdder]
tenet.sink.topic-name=test_demo
tenet.sink.dialect-name=MongoDatabaseDialect
tenet.sink.connection-url=mongodb://root:123456@127.0.0.1:27017/kafka_demo?authSource=admin
tenet.sink.database=kafka_demo
tenet.sink.retry-backoff=3000
tenet.sink.target-topic=test_demo1
tenet.schema.file-path=schema.json
tenet.sink.max-queue=80
# tenet.sink.connection-url=jdbc:mysql://127.0.0.1:13306/demo
#special for mongo
#tenet.sink.metric-reporters=org.apache.kafka.common.metrics.JmxReporter
#tenet.sink.metrics-num-samples=1
#tenet.sink.metrics-recording-level=INFO
#tenet.sink.metrics-sample-window=30000
tenet.sink.limiting-every-n=0
tenet.sink.limiting-timeout=3000
teent.sink.write-model-strategy=io.ctsi.tenet.kafka.mongodb.sink.writemodel.strategy.ReplaceOneDefaultStrategy
